{
  "id": "1",
  "title": "Filter Adults",
  "difficulty": "Easy",
  "category": "Filtering",
  "description": "# Filter Adults\n\nGiven a DataFrame with columns `Name` and `Age`, filter it to keep only people older than 18.\n\n## Input Schema\n\n| Column | Type |\n|--------|------|\n| Name | string |\n| Age | integer |\n\n## Expected Output\n\nA DataFrame containing only rows where `Age > 18`.",
  "starter_code": "def solve(df):\n    # Write your transformation here\n    # return df.filter(...)\n    pass",
  "test_setup": "from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\n\nspark = SparkSession.builder.appName('test').getOrCreate()\n\ndata = [('Alice', 25), ('Bob', 10), ('Charlie', 30)]\ncolumns = ['Name', 'Age']\ndf = spark.createDataFrame(data, columns)",
  "test_validation": "result = solve(df)\nassert result is not None, 'Function returned None'\nassert result.count() == 2, f'Expected 2 rows, got {result.count()}'\nassert result.filter(result.Age <= 18).count() == 0, 'Found minors in result'\nprint('âœ… TEST PASSED!')",
  "hints": [
    "Use the filter() method on the DataFrame",
    "The condition should check if Age > 18",
    "You can use df.filter(df.Age > 18) or df.filter(F.col('Age') > 18)"
  ],
  "solution": "def solve(df):\n    return df.filter(df.Age > 18)"
}
