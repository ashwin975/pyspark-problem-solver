{
  "id": "15",
  "title": "Author Row Numbers",
  "difficulty": "Medium",
  "category": "Window Functions",
  "description": "**Research Papers**\n\nYou have two DataFrames: `research_papers` and `authors`.\n\n**research_papers:** paper_id, title, year\n**authors:** paper_id, author_id, name\n\nAdd a `row_number` column to authors that assigns a unique row number to each author within their paper, ordered by author_id.\n\n**Example Output:**\n| paper_id | author_id | name  | row_number |\n|----------|-----------|-------|------------|\n| P1       | A1        | Alice | 1          |\n| P1       | A2        | Bob   | 2          |\n| P2       | A3        | Carol | 1          |",
  "starter_code": "def etl(research_papers, authors):\n    # Write code here\n    pass",
  "test_setup": "from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import Window as W\n\nspark = SparkSession.builder.appName('test').getOrCreate()\n\npapers_data = [('P1', 'ML Study', 2023), ('P2', 'Data Analysis', 2022)]\nresearch_papers = spark.createDataFrame(papers_data, ['paper_id', 'title', 'year'])\n\nauthors_data = [('P1', 'A1', 'Alice'), ('P1', 'A2', 'Bob'), ('P2', 'A3', 'Carol'), ('P2', 'A1', 'Alice')]\nauthors = spark.createDataFrame(authors_data, ['paper_id', 'author_id', 'name'])",
  "test_validation": "result = etl(research_papers, authors)\nassert result is not None, 'Function returned None'\nassert 'row_number' in result.columns, 'Missing row_number column'\nprint('âœ… TEST PASSED!')",
  "hints": [
    "Create Window with partitionBy and orderBy",
    "Use F.row_number().over(window)",
    "Row numbers restart at 1 for each partition"
  ],
  "solution": "def etl(research_papers, authors):\n    author_window = W.partitionBy('paper_id').orderBy('author_id')\n    result = authors.withColumn(\n        'row_number',\n        F.row_number().over(author_window)\n    )\n    return result"
}
