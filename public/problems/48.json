{
  "id": "48",
  "title": "Conditional Aggregation",
  "difficulty": "Medium",
  "category": "Aggregations",
  "description": "Sum values conditionally using when inside aggregation.\n\nYou have a DataFrame with `category`, `status`, and `amount` columns. Group by category and calculate:\n- `active_total`: sum of amount where status is 'active'\n- `inactive_total`: sum of amount where status is 'inactive'",
  "starter_code": "def etl(input_df):\n    # Write code here\n    pass",
  "test_setup": "from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import Window as W\n\nspark = SparkSession.builder.appName('test').getOrCreate()\n\ndata = [\n    ('A', 'active', 100), ('A', 'active', 150),\n    ('A', 'inactive', 50), ('B', 'active', 200),\n    ('B', 'inactive', 75), ('B', 'inactive', 25)\n]\ninput_df = spark.createDataFrame(data, ['category', 'status', 'amount'])",
  "test_validation": "result = etl(input_df)\nassert result is not None, 'Function returned None'\nassert 'active_total' in result.columns, 'Missing active_total column'\nassert 'inactive_total' in result.columns, 'Missing inactive_total column'\nprint('âœ… TEST PASSED!')",
  "hints": [
    "Put when inside sum",
    "Use otherwise(0) for non-matching"
  ],
  "solution": "def etl(input_df):\n    return input_df.groupBy('category').agg(\n        F.sum(F.when(F.col('status') == 'active', F.col('amount')).otherwise(0)).alias('active_total'),\n        F.sum(F.when(F.col('status') == 'inactive', F.col('amount')).otherwise(0)).alias('inactive_total')\n    )"
}
