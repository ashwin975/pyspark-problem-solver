{
  "id": "52",
  "title": "Order By Multiple Columns",
  "difficulty": "Easy",
  "category": "Transformations",
  "description": "Sort DataFrame by multiple columns with mixed order.\n\nYou have a DataFrame with `category` and `date` columns. Sort by category ascending, then by date descending.",
  "starter_code": "def etl(input_df):\n    # Write code here\n    pass",
  "test_setup": "from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import Window as W\n\nspark = SparkSession.builder.appName('test').getOrCreate()\n\ndata = [\n    ('B', '2023-01-01'), ('A', '2023-01-02'),\n    ('A', '2023-01-01'), ('B', '2023-01-02')\n]\ninput_df = spark.createDataFrame(data, ['category', 'date'])",
  "test_validation": "result = etl(input_df)\nassert result is not None, 'Function returned None'\nrows = result.collect()\nassert rows[0]['category'] == 'A', 'First row should be category A'\nassert rows[0]['date'] == '2023-01-02', 'First A row should have latest date'\nprint('âœ… TEST PASSED!')",
  "hints": [
    "F.col('name').asc() for ascending",
    "F.col('name').desc() for descending",
    "Can mix in same orderBy"
  ],
  "solution": "def etl(input_df):\n    return input_df.orderBy(\n        F.col('category').asc(),\n        F.col('date').desc()\n    )"
}
