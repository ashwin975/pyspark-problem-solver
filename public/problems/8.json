{
  "id": "8",
  "title": "Call Center Aggregation",
  "difficulty": "Medium",
  "category": "Aggregations",
  "description": "**Call Center**\n\nYou have two DataFrames: `calls_df` and `customers_df`.\n\n**calls_df Schema:**\n| Column   | Type    |\n|----------|---------|\n| call_id  | integer |\n| cust_id  | integer |\n| date     | string  |\n| duration | integer |\n\n**customers_df Schema:**\n| Column     | Type    |\n|------------|---------|\n| cust_id    | integer |\n| name       | string  |\n| state      | string  |\n| tenure     | integer |\n| occupation | string  |\n\nReturn the number of distinct customers and total duration of calls per date.\n\n**Output Schema:**\n| Column         | Type    |\n|----------------|---------|\n| date           | string  |\n| num_customers  | integer |\n| total_duration | integer |",
  "starter_code": "def etl(calls_df, customers_df):\n    # Write code here\n    pass",
  "test_setup": "from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import Window as W\n\nspark = SparkSession.builder.appName('test').getOrCreate()\n\ncalls_data = [\n    (1, 101, '2023-01-01', 300),\n    (2, 102, '2023-01-01', 450),\n    (3, 101, '2023-01-01', 200),\n    (4, 103, '2023-01-02', 600),\n    (5, 101, '2023-01-02', 150)\n]\ncalls_df = spark.createDataFrame(calls_data, ['call_id', 'cust_id', 'date', 'duration'])\n\ncustomers_data = [\n    (101, 'Alice', 'CA', 5, 'Engineer'),\n    (102, 'Bob', 'NY', 3, 'Manager'),\n    (103, 'Carol', 'TX', 2, 'Analyst')\n]\ncustomers_df = spark.createDataFrame(customers_data, ['cust_id', 'name', 'state', 'tenure', 'occupation'])",
  "test_validation": "result = etl(calls_df, customers_df)\nassert result is not None, 'Function returned None'\nassert 'date' in result.columns, 'Missing date column'\nassert 'num_customers' in result.columns, 'Missing num_customers column'\nassert 'total_duration' in result.columns, 'Missing total_duration column'\nprint('âœ… TEST PASSED!')",
  "hints": [
    "Join on cust_id first",
    "Use F.count_distinct() for unique customer count",
    "Use F.sum() for total duration"
  ],
  "solution": "def etl(calls_df, customers_df):\n    joined_df = calls_df.join(customers_df, 'cust_id')\n    \n    agg_df = joined_df.groupby('date').agg(\n        F.count_distinct('cust_id').alias('num_customers'),\n        F.sum('duration').alias('total_duration')\n    )\n    \n    return agg_df"
}
